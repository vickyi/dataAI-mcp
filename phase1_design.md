# 阶段一设计文档

## 目标
优先解决 SQL 自动生成问题，增强对数据表结构的理解能力

## 所需数据仓库支持

### 1. 元数据信息

#### 表结构元数据
- **表名清单**：所有数据表的名称和所属数据库
- **表结构定义**：每个表的字段名、数据类型、是否可为空等信息
- **表注释说明**：表的业务含义和用途描述
- **分区信息**：表的分区字段和分区策略

#### 字段元数据
- **字段详细信息**：字段名称、数据类型、长度、精度等
- **字段业务含义**：字段的业务解释和使用场景
- **字段约束**：主键、外键、唯一性约束等
- **字段敏感性标识**：标识敏感字段（如手机号、身份证号等）

### 2. 数据血缘关系

#### 表间关联关系
- **外键关系**：表之间的外键关联信息
- **业务关联**：基于业务逻辑的表关联关系
- **ETL血缘**：数据表的来源和去向关系
- **依赖关系**：表之间的依赖和影响关系

#### 数据流信息
- **数据来源**：原始数据的采集来源
- **数据加工过程**：数据经过的处理步骤
- **数据去向**：数据的最终使用场景

### 3. 业务语义信息

#### 业务术语库
- **业务词汇表**：标准化的业务术语和定义
- **指标字典**：关键业务指标的计算方法和含义
- **维度信息**：业务分析维度的定义和取值

#### 业务场景映射
- **场景与表映射**：不同业务场景涉及的数据表
- **场景与字段映射**：业务场景关注的核心字段
- **典型查询模式**：常见的数据分析模式

### 4. 数据质量信息

#### 数据质量指标
- **数据完整性**：数据的完整性和覆盖率
- **数据准确性**：数据的准确性和一致性
- **数据时效性**：数据更新频率和时效性

#### 数据分布统计
- **数据量统计**：各表的数据量级信息
- **字段值分布**：关键字段的值分布情况
- **数据更新频率**：数据的更新周期和时间

### 5. 使用统计信息

#### 查询历史
- **常用查询模式**：历史查询的统计分析
- **高频表和字段**：使用频率最高的表和字段
- **查询性能数据**：历史查询的执行性能

#### 用户行为数据
- **用户偏好**：不同用户的使用习惯
- **访问模式**：用户访问数据的模式和路径

## 数据访问和使用方案

### 1. 数据源连接配置

#### MySQL数据库连接
- **bigdata_db库**：包含数仓各层（ods/dw/dim/dws/app）数据表、字段和注释信息
- **user_profile_db库**：包含用户画像相关表结构和业务语义信息
- **连接方式**：使用Python的mysql-connector-python或PyMySQL库建立连接
- **认证信息**：通过环境变量或配置文件安全存储数据库连接凭证

#### 血缘关系数据访问
- **ETL解析数据**：从user_profile_db中获取基于大数据ETL解析的表血缘关系
- **数据结构**：包含源表、目标表、字段映射关系、转换规则等信息

### 2. 数据采集和处理

#### 元数据采集SQL
```sql
-- 采集表结构和注释信息
SELECT
    table_schema,
    table_name,
    column_name,
    data_type,
    is_nullable,
    column_comment
FROM information_schema.columns
WHERE table_schema IN ('ods', 'dw', 'dim', 'dws', 'app');

-- 采集表注释信息
SELECT
    table_schema,
    table_name,
    table_comment
FROM information_schema.tables
WHERE table_schema IN ('ods', 'dw', 'dim', 'dws', 'app');
```

#### 血缘关系采集SQL
```sql
-- 采集表间血缘关系
SELECT
    source_table,
    target_table,
    source_column,
    target_column,
    transform_rule
FROM data_lineage_table_relations;

-- 采集ETL任务信息
SELECT
    job_name,
    source_tables,
    target_tables,
    schedule_frequency
FROM etl_job_metadata;
```

### 3. 数据存储和管理

#### 本地数据存储
- **SQLite数据库**：在项目本地建立SQLite数据库存储采集的元数据
- **数据表设计**：
  - tables_meta：存储表元数据信息
  - columns_meta：存储字段元数据信息
  - table_lineage：存储表间血缘关系
  - business_terms：存储业务术语信息

#### 数据更新机制
- **定时同步**：设置定时任务定期从MySQL库同步最新元数据
- **增量更新**：只同步发生变化的元数据，提高效率
- **缓存机制**：使用内存缓存提高数据访问速度

### 4. 数据使用方式

#### AI模型训练数据准备
- **特征工程**：将元数据转换为AI模型可理解的特征向量
- **标签构建**：基于历史查询日志构建训练样本标签
- **数据集划分**：按业务场景划分训练集、验证集和测试集

#### 实时查询支持
- **元数据查询API**：提供RESTful API接口查询表结构和血缘关系
- **语义理解增强**：在SQL生成过程中实时查询相关元数据信息
- **智能推荐引擎**：基于用户输入和元数据提供表和字段推荐

## 代码实现方案

### 1. 项目结构扩展
在现有项目结构基础上，新增以下模块：
```
src/
├── utils/
│   ├── db_config.py          # 数据库配置管理
│   └── metadata_collector.py # 元数据采集器
tests/
└── test_metadata_collector.py # 元数据采集器测试
```

### 2. 核心组件实现

#### 数据库配置管理 (db_config.py)
- 实现DatabaseConfig类管理多个MySQL数据库连接配置
- 支持通过环境变量配置数据库连接参数
- 提供获取连接字符串的方法

#### 元数据采集器 (metadata_collector.py)
- 实现MetadataCollector类负责元数据采集和存储
- 支持从MySQL数据库采集表结构、字段信息和血缘关系
- 实现本地SQLite数据库存储，提高查询效率
- 提供元数据同步方法

### 3. 依赖管理
在requirements.txt中添加PyMySQL依赖，用于连接MySQL数据库

### 4. 测试方案
创建test_metadata_collector.py测试文件，验证元数据采集功能

## 实现阶段一目标的步骤

### 1. 数据接入和处理
1. 建立与数据仓库的连接机制
2. 设计元数据采集方案
3. 实现数据解析和存储

### 2. AI模型增强
1. 训练模型理解业务需求与数据表的映射关系
2. 增强模型对表结构和字段含义的理解能力
3. 优化SQL生成算法，提高准确率

### 3. 功能实现
1. 实现数据表元数据管理
2. 添加表结构自动识别功能
3. 支持表字段含义解释
4. 建立表间关联关系图谱

### 4. 智能推荐功能
1. 根据业务需求推荐相关数据表
2. 自动生成表连接关系建议
3. 提供字段使用建议

## 预期成果
1. SQL 自动生成准确率提升至 85% 以上
2. 实现表结构和字段含义的自动识别
3. 建立表间关联关系图谱
4. 提供智能推荐功能，帮助用户选择合适的表和字段